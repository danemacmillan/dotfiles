#user nobody;
worker_processes auto;
#worker_rlimit_nofile 40000;

events {
    #use kqueue;
    worker_connections 8192;
    multi_accept on;
    #use epoll;
}

http {
    include mime.types;
    default_type application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';

    error_log /usr/local/var/log/nginx/error.log warn;
    access_log /usr/local/var/log/nginx/access.log main;

    # Basic Settings
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    #types_hash_max_size 2048;
    charset UTF-8;

    client_body_buffer_size 10K;
    client_header_buffer_size 10;
    client_max_body_size 200m;
    large_client_header_buffers 4 8k;

    client_body_timeout 30;
    client_header_timeout 30;
    send_timeout 30;
    # Need to be different behind a GCP HTTPS load balancer:
    # https://blog.percy.io/tuning-nginx-behind-google-cloud-platform-http-s-load-balancer-305982ddb340#.t62ms83tr
    ##keepalive_requests 500;
    keepalive_requests 10000;
    ##keepalive_timeout 30 30;
    keepalive_timeout 650;
    reset_timedout_connection on;

    open_file_cache max=15000 inactive=200s;
    open_file_cache_valid 3600s;
    open_file_cache_min_uses 3;
    open_file_cache_errors on;

    server_tokens off;
    # server_names_hash_bucket_size 64;
    #server_name_in_redirect off;
    #etag off;
    #disable_symlinks off;
    #autoindex off;

    # Gzip Settings
    gzip on;
    gzip_comp_level 7;
    gzip_proxied any;
    gzip_types text/plain text/xml text/css application/x-javascript text/javascript application/javascript application/xml+rss application/json image/x-icon image/bmp font/opentype application/font-woff application/vnd.ms-fontobject;
    gzip_vary on;
    gzip_disable "msie6";
    gzip_static on;
    gzip_min_length  4000;
    gzip_buffers 512 4k;
    gzip_http_version 1.1;

    #limit_req_zone  $binary_remote_addr  zone=one:10m   rate=8r/s;

    # Universal headers that should not be duplicated.
    include headers.conf;

    # Buffering
    #
    # Handle proxy buffering responses to reduce temporary writes to filesystem.
    # Common warning: "an upstream response is buffered to a temporary file
    # /var/cache/nginx/proxy_temp/4/81/0000023814 while reading upstream"
    # If you know clients can handle
    proxy_buffering on;
    # Set buffer for initial header response (usually small). Bear in mind
    # that other processes, like Varnish, could be adding and removing
    # headers, or setting large cookies. 4k is probably safe enough.
    # Note that M2 Varnish sets a large cache header for purge requests.
    proxy_buffer_size 32k;
    # Most image thumbnails are between 5kb and 15kb. Most documents (though
    # handled by the fastcgi_* buffer parameters that mirror the proxy_* ones),
    # are between 120kb and 260kb. Eensure it can all be buffered into memory
    # instead of temporarily written to disk. The best way to determine memory
    # allocation is to think of proxy_buffers as a property of a single request.
    # If most respones can be anywhere between 5kb and 260kb, with many images
    # on the low end, memory should be allocated as efficiently as possible. In
    # other words, for each request we have up, for example, 32 buffers, each
    # at 16k each, or 32*16k=512kb. If an image is 12kb, it will only allocate
    # a single buffer of 16k to handle it. If the buffer size was 512kb with
    # only 1 buffer defined (1 512k), that would mean nginx would allocated
    # 512kb of memory for a measly little image. That's not very efficient. By
    # breaking down the buffer size, it helps nginx optimize each response in
    # memory. That means an image of 12kb will only take up 1 16k buffer, while
    # a document that is 260kb will occupy 17 16k buffers. A very large image
    # that is 400kb will occupy 25 16k buffers.
    proxy_buffers 64 16k;
    proxy_busy_buffers_size 256k;
    proxy_max_temp_file_size 200m;
    proxy_temp_file_write_size 1024k;

    # Have this match PHP execution timeout (4002) and add a bit more. Given
    # that upstreams are proxied, it should not timeout before the upstream
    # times out or errors out. This was causing issues on M2 admin when moving
    # large categories.
    proxy_read_timeout 4004;

    # Virtual Host Configs
    include servers/*.conf;
}
